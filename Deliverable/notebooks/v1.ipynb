{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Concepts and Principles\n",
    "## Software Defect Detection\n",
    "\n",
    "> Lazaros Panitsidis & Konstantinos Kravaritis<br />\n",
    "> MSc Data Science <br />\n",
    "> International Hellenic University <br />\n",
    "> lpanitsidis@ihu.edu.gr & kkravaritis@ihu.edu.gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. [Useful Python Libraries](#0)\n",
    "1. [Data Content](#1)\n",
    "1. [Feature Engineering](#2)\n",
    "     1. [Data Preprocessing](#3)\n",
    "     1. [Visualization & Analysis](#4)\n",
    "1. [Feature Selection and Random Forest Classification](#5)\n",
    "     1. [Feature Selection by Correlation](#6)\n",
    "     1. [Univariate feature selection (SelectKbest)](#7)\n",
    "     1. [Recursive Feature Elimination (RFE)](#8)\n",
    "     1. [Recursive Feature Elimination with Cross-Validation (RFECV)](#9)\n",
    "     1. [Feature importances with a forest of trees](#10)\n",
    "     1. [XGBoost Feature Importances](#11)\n",
    "     1. [Minimum Redundancy & Maximum Relevance](#12)\n",
    "1. [Feature extraction with PCA](#11)\n",
    "1. [Summary](#12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "## Useful Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Numeric operations & plots ###\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np # linear algebra\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns # data visualization library  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Validation & Normalization methods ###\n",
    "from sklearn.model_selection import cross_val_score , GridSearchCV , StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "### ML models ###\n",
    "from sklearn.linear_model import LogisticRegression # C1\n",
    "from sklearn.linear_model import SGDClassifier # C1 loss: log_loss => LogisticRegression with SGD\n",
    "from sklearn.linear_model import Perceptron # C2\n",
    "from sklearn.svm import SVC # C3\n",
    "from sklearn.tree import DecisionTreeClassifier # C4\n",
    "from sklearn.ensemble import RandomForestClassifier # C5\n",
    "from sklearn.neural_network import MLPClassifier # C6\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "### Metrics ###\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, make_scorer, classification_report\n",
    "from imblearn.metrics import geometric_mean_score # https://imbalanced-learn.org/stable/references/generated/imblearn.metrics.geometric_mean_score.html\n",
    "import time\n",
    "import timeit # https://stackoverflow.com/questions/17579357/time-time-vs-timeit-timeit\n",
    "\n",
    "### Pipeline ###\n",
    "from sklearn.pipeline import make_pipeline , Pipeline # https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "### Custom Modules ###\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from functions.data_types import optimize_dtypes\n",
    "from functions.dataframe_actions import df_info\n",
    "\n",
    "### Settings ###\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "#import warnings library\n",
    "import warnings\n",
    "# ignore all warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe information\n",
    "def df_info(dataframes):\n",
    "  \"\"\"\n",
    "    Finds some usefull information about all dataframes given in the function.\n",
    "    \n",
    "    Usage: pass a list of dataframes into the function\n",
    "    dataframes = [df1,df2,...]\n",
    "  \"\"\"\n",
    "\n",
    "  for df in dataframes:\n",
    "         # Check if the dataframe has at least one column\n",
    "        if not df.empty:\n",
    "          # # Use list comprehension to get the name of the dataframe from global variables\n",
    "          df_name = [name for name, obj in globals().items() if obj is df][0] # [0] is the name of each dataframe in the list\n",
    "          print(\"----- information for \", df_name, \" -----\")\n",
    "          print(df_name, \" : \", df.shape, \"(rows, columns)\")\n",
    "          print(df_name, \" : \", df.isna().sum().sum() , \"missing values\")\n",
    "          print(df_name, \" : \", df.duplicated().sum() , \"duplicated values\")\n",
    "          #df.describe()\n",
    "          #df.info()\n",
    "          \n",
    "          # Identify and count values of the last column\n",
    "          last_column = df.columns[-1]\n",
    "          value_counts = df[last_column].value_counts()\n",
    "\n",
    "          print(df_name, \" : Value counts for \", last_column)\n",
    "          print(value_counts)\n",
    "        else:\n",
    "          print(df_name, ': The dataframe is empty.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read .csv files from another directory\n",
    "data_location = \"../../\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read the .csv files and make dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jm1 = pd.read_csv(data_location + \"jm1.csv\")\n",
    "mc1 = pd.read_csv(data_location + \"mc1.csv\")\n",
    "pc3 = pd.read_csv(data_location + \"pc3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract useful information about the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- information for  jm1  -----\n",
      "jm1  :  (10885, 22) (rows, columns)\n",
      "jm1  :  0 missing values\n",
      "jm1  :  1973 duplicated values\n",
      "jm1  : Value counts for  defects\n",
      "defects\n",
      "False    8779\n",
      "True     2106\n",
      "Name: count, dtype: int64\n",
      "----- information for  mc1  -----\n",
      "mc1  :  (9466, 39) (rows, columns)\n",
      "mc1  :  0 missing values\n",
      "mc1  :  7450 duplicated values\n",
      "mc1  : Value counts for  c\n",
      "c\n",
      "False    9398\n",
      "True       68\n",
      "Name: count, dtype: int64\n",
      "----- information for  pc3  -----\n",
      "pc3  :  (1563, 38) (rows, columns)\n",
      "pc3  :  0 missing values\n",
      "pc3  :  124 duplicated values\n",
      "pc3  : Value counts for  c\n",
      "c\n",
      "False    1403\n",
      "True      160\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataframes = [jm1, mc1, pc3]\n",
    "df_info(dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding with sklearn's LabelEncoder\n",
    "class_le = LabelEncoder()\n",
    "jm1['defects'] = class_le.fit_transform(jm1['defects'].values)\n",
    "mc1['c'] = class_le.fit_transform(mc1['c'].values)\n",
    "pc3['c'] = class_le.fit_transform(pc3['c'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find optimal data types for faster computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "jm1 = optimize_dtypes(jm1)\n",
    "mc1 = optimize_dtypes(mc1)\n",
    "pc3 = optimize_dtypes(pc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loc                  float16\n",
       "v(g)                 float16\n",
       "ev(g)                float16\n",
       "iv(g)                float16\n",
       "n                    float16\n",
       "v                    float32\n",
       "l                    float16\n",
       "d                    float16\n",
       "i                    float16\n",
       "e                    float32\n",
       "b                    float16\n",
       "t                    float32\n",
       "lOCode                uint16\n",
       "lOComment             uint16\n",
       "lOBlank               uint16\n",
       "locCodeAndComment      uint8\n",
       "uniq_Op               object\n",
       "uniq_Opnd             object\n",
       "total_Op              object\n",
       "total_Opnd            object\n",
       "branchCount           object\n",
       "defects                uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jm1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up scoring and cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple metrics\n",
    "scoring = {'Accuracy': make_scorer(accuracy_score),\n",
    "           'F1-score': make_scorer(f1_score, average='binary'),\n",
    "           'G-Mean score': make_scorer(geometric_mean_score, average='binary')\n",
    "          }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
