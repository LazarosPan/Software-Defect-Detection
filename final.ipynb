{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Concepts and Principles\n",
    "## Software Defect Detection\n",
    "\n",
    "> Lazaros Panitsidis & Konstantinos Kravaritis<br />\n",
    "> MSc Data Science <br />\n",
    "> International Hellenic University <br />\n",
    "> lpanitsidis@ihu.edu.gr & kkravaritis@ihu.edu.gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. [Useful Python Libraries](#0)\n",
    "1. [Data Content](#1)\n",
    "1. [Feature Engineering](#2)\n",
    "     1. [Data Preprocessing](#3)\n",
    "     1. [Visualization & Analysis](#4)\n",
    "1. [Feature Selection and Random Forest Classification](#5)\n",
    "     1. [Feature Selection by Correlation](#6)\n",
    "     1. [Univariate feature selection (SelectKbest)](#7)\n",
    "     1. [Recursive Feature Elimination (RFE)](#8)\n",
    "     1. [Recursive Feature Elimination with Cross-Validation (RFECV)](#9)\n",
    "     1. [Feature importances with a forest of trees](#10)\n",
    "     1. [XGBoost Feature Importances](#11)\n",
    "     1. [Minimum Redundancy & Maximum Relevance](#12)\n",
    "1. [Feature extraction with PCA](#11)\n",
    "1. [Summary](#12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "## Useful Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns # data visualization library  \n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "#import warnings library\n",
    "import warnings\n",
    "# ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "### Validation & Normalization methods ###\n",
    "from sklearn.model_selection import cross_val_score , GridSearchCV , StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "### ML models ###\n",
    "from sklearn.linear_model import LogisticRegression # C1\n",
    "from sklearn.linear_model import SGDClassifier # C1 loss: log_loss => LogisticRegression with SGD\n",
    "from sklearn.linear_model import Perceptron # C2\n",
    "from sklearn.svm import SVC # C3\n",
    "from sklearn.tree import DecisionTreeClassifier # C4\n",
    "from sklearn.ensemble import RandomForestClassifier # C5\n",
    "from sklearn.neural_network import MLPClassifier # C6\n",
    "\n",
    "### Metrics ###\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score , make_scorer , classification_report\n",
    "import timeit # https://stackoverflow.com/questions/17579357/time-time-vs-timeit-timeit\n",
    "\n",
    "\n",
    "### Pipeline ###\n",
    "from sklearn.pipeline import make_pipeline , Pipeline # https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "\n",
    "### Custom Modules ###\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from functions.data_types import optimize_dtypes\n",
    "from functions.dataframe_actions import df_info, df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read the .csv files and make dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read .csv files from another directory\n",
    "data_location = \"\" # /<path>\n",
    "\n",
    "jm1 = pd.read_csv(data_location + \"jm1.csv\")\n",
    "mc1 = pd.read_csv(data_location + \"mc1.csv\")\n",
    "pc3 = pd.read_csv(data_location + \"pc3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean the dataframes from non-numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows that cointain non numeric valeus\n",
    "jm1 = df_clean(jm1)\n",
    "mc1 = df_clean(mc1)\n",
    "pc3 = df_clean(pc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract useful information about the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- information for  jm1  -----\n",
      "jm1  :  (10880, 22) (rows, columns)\n",
      "jm1  :  0 missing values\n",
      "jm1  :  1973 duplicated values\n",
      "jm1  : Value counts for  defects\n",
      "defects\n",
      "False    8777\n",
      "True     2103\n",
      "Name: count, dtype: int64\n",
      "----- information for  mc1  -----\n",
      "mc1  :  (9466, 39) (rows, columns)\n",
      "mc1  :  0 missing values\n",
      "mc1  :  7450 duplicated values\n",
      "mc1  : Value counts for  c\n",
      "c\n",
      "False    9398\n",
      "True       68\n",
      "Name: count, dtype: int64\n",
      "----- information for  pc3  -----\n",
      "pc3  :  (1563, 38) (rows, columns)\n",
      "pc3  :  0 missing values\n",
      "pc3  :  124 duplicated values\n",
      "pc3  : Value counts for  c\n",
      "c\n",
      "False    1403\n",
      "True      160\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataframes = [jm1, mc1, pc3]\n",
    "dataframe_names = [\"jm1\", \"mc1\", \"pc3\"]\n",
    "df_info(dataframes, dataframe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find optimal data types for faster computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jm1 = optimize_dtypes(jm1)\n",
    "mc1 = optimize_dtypes(mc1)\n",
    "pc3 = optimize_dtypes(pc3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
